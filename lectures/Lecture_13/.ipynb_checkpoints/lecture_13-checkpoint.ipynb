{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture #13: Model Selection and Parallel Tempering\n",
    "## AM 207: Advanced Scientific Computing\n",
    "### Stochastic Methods for Data Analysis, Inference and Optimization\n",
    "### Fall, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"fig/logos.jpg\" style=\"height:150px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### Import basic libraries\n",
    "from autograd import numpy as np\n",
    "from autograd import grad\n",
    "import numpy\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import rc\n",
    "from IPython.display import HTML\n",
    "from IPython.display import YouTubeVideo\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Administrative Matters\n",
    "\n",
    "1. **Attendance Quiz:** \n",
    "2. **Projects:** Project mentors will be announced on Canvas (there will be one TF assigned for each paper). Set up times to meet with your project mentor and instrctur (together or separately) - see Check Point #2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "1. Model Selection for Hierachical Generalized Linear Models\n",
    "2. MCMC Diagnostics\n",
    "3. Parallel Tempering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Selection for Hierachical Generalized Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How Many Covariates to Include?\n",
    "\n",
    "Now we can inject covariates into any distribution $Y^{(n)} \\sim p(Y | \\theta)$, by making $\\theta$ a function of $\\mathbf{X}$. Doing so allows us to explain the distribution of the outcome $Y$ based on explanatory factors $\\mathbf{X}$. \n",
    "\n",
    "In fact, **the more covaraiates you use, the better your model will fit the data**. \n",
    "\n",
    "But interpreting the model becomes problemmatic when the covariates are not independent of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Dangers of Model Interpretation\n",
    "\n",
    "For example, suppose that you are modeling kidney cancer using a logistic regression model with $\\mathbf{X} = \\{\\text{age}, \\text{smoker}\\}$. Suppose that the maximum likelihood model you found is\n",
    "\n",
    "$$\n",
    "\\mathrm{Prob}[Y = 1| \\mathbf{X}, \\mathbf{w}] = \\mathrm{sigm}(-5 * \\text{age} - 0.2 * \\text{smoker} - 0.5)\n",
    "$$\n",
    "\n",
    "What happens if you included more covariates: $\\mathbf{X} = \\{\\text{age}, \\text{video games (hr)}, \\text{smoker}\\}$? If the new covariates are correlated with existing ones, e.g. \n",
    "\n",
    "$$\\text{video games (hr)} = 0.5 * \\text{age},$$ \n",
    "\n",
    "then the model weights can change drastically:\n",
    "\n",
    "$$\n",
    "\\mathrm{Prob}[Y = 1| \\mathbf{X}, \\mathbf{w}] = \\mathrm{sigm}(0.5 * \\text{age} - 11 * \\text{video games (hr)} - 0.2 * \\text{smoker} - 0.5)\n",
    "$$\n",
    "\n",
    "Note, both models will fit the observed data equally well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Selection through Cross-Validation\n",
    "If one of these models captures the true relationship between the covariates and the risk of kidney cancer, then it will ***generalize*** (fit new data) well.\n",
    "\n",
    "\\begin{align}\n",
    "(\\text{Model 1})\\quad \\mathrm{Prob}[Y = 1| \\mathbf{X}, \\mathbf{w}] &= \\mathrm{sigm}(-5 * \\text{age} - 0.2 * \\text{smoker} - 0.5)\\\\\n",
    "(\\text{Model 2})\\quad \\mathrm{Prob}[Y = 1| \\mathbf{X}, \\mathbf{w}] &= \\mathrm{sigm}(0.5 * \\text{age} - 11 * \\text{games} - 0.2 * \\text{smoker} - 0.5)\n",
    "\\end{align}\n",
    "\n",
    "In other words, if one of these models is capturing spurious connections between the covariates and the outcome, then it should fail on new data where this connection doesn't hold (e.g. when we collect data on older individuals who play a lot of video games).\n",
    "\n",
    "One way to simulate the model's performance on new data is to randomnly hold-out different parts of the observed data during inference (we train on the remaining data) and use the held-out data to test the performance of the model. We select the model that has the best performance, on average, on held-out data. This is called ***cross-validation***. \n",
    "\n",
    "Note: in cross validation you are re-training your model multiple times. This can be prohibitively expensive!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Selection for Maximum Likelihood Models\n",
    "\n",
    "An alternative to model selection via cross-validation is to directly approximate the model's performance on new data. We evaluate predictive accuracy using the log-likelihood of the observed data:\n",
    "$$\n",
    "D(y|\\mathbf{w}_{\\text{MLE}}) = -2\\sum_{n=1}^N\\log p\\left(Y^{(n)}|\\mathbf{X}^{(n)}, \\mathbf{w}_{\\text{MLE}}\\right)\n",
    "$$\n",
    "We know that this is an overestimate of the log-likelihood of new data under the model. So a correction must be made. This correction is typically the complexity of the model, i.e. the dimension of $\\mathbf{w}$:\n",
    "\n",
    "1. (**Akaike's Information Criterion**) $$\\text{AIC} = D(y|\\mathbf{w}_{\\text{MLE}}) + 2\\,\\mathrm{dim}(\\mathbf{w}_{\\text{MLE}})$$\n",
    "\n",
    "2. (**Bayesian Information Criterion**) $$\\text{BIC} = D(y|\\mathbf{w}_{\\text{MLE}}) + \\log(N)\\,\\mathrm{dim}(\\mathbf{w}_{\\text{MLE}})$$\n",
    "\n",
    "The smaller the number the better.\n",
    "\n",
    "The validity of each criterion is argued asymptotically, assuming a number of specific modeling conditions -- in practice, use with caution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Selection for Bayesian Models\n",
    "\n",
    "For Bayesian models we evaluate the predictive accuracy using the (point-wise) log posterior predictive likelihood (lppd) of the observed data:\n",
    "\n",
    "$$\n",
    "\\mathrm{lppd} = \\sum_{n=1}^N\\log \\int p\\left(Y^{(n)}|\\mathbf{X}^{(n)}, \\mathbf{w}\\right) p(\\mathbf{w} | \\text{Data}) d\\mathbf{w} = \\sum_{n=1}^N\\log\\mathbb{E}_{\\mathbf{w} \\sim p(\\mathbf{w} | \\text{Data})}\\left[p\\left(Y^{(n)}|\\mathbf{X}^{(n)}, \\mathbf{w}\\right) \\right].\n",
    "$$\n",
    "\n",
    "Again, this is an overestimate of the log-likelihood of new data under the posterior. So a correction must be made. In this case, the correction is the (point-wise) variance of the log posterior predictive likelihood\n",
    "\n",
    "$$\n",
    "p_{\\text{WAIC}} = \\sum_{n=1}^N\\log\\mathrm{Var}_{\\mathbf{w} \\sim p(\\mathbf{w} | \\text{Data})}\\left[p\\left(Y^{(n)}|\\mathbf{X}^{(n)}, \\mathbf{w}\\right) \\right].\n",
    "$$\n",
    "\n",
    "The ***Watanabe-Akaike information criterion (WAIC)*** is defined to be\n",
    "\n",
    "$$\n",
    "\\mathrm{WAIC} = -2\\, \\mathrm{lppd} + 2\\, p_{\\text{WAIC}}.\n",
    "$$\n",
    "\n",
    "One may interpret $p_{\\text{WAIC}}$ as an approximation of the effective number of parameters in the model (in a complex hierarchical model the \"number of parameters\" is not obvious to quantify)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MCMC Diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hamiltonian Monte Carlo (HMC)\n",
    "\n",
    "We use the ***Gibbs distribution*** to transform between probability density functions and energy functions\n",
    "$$\n",
    "U(q) = - \\log \\pi(q), \\quad \\pi(q) = \\frac{1}{Z}\\exp\\left\\{ \\frac{-U(q)}{T}\\right\\},\\; T=1\n",
    "$$\n",
    "This allows us to use gradient information when we sample from $\\pi(q)$.\n",
    "\n",
    "<img src=\"fig/hamiltonian.jpg\" style=\"height:300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What's Important About HMC?\n",
    "\n",
    "1. **Question:** HMC seems complicated, do I really need to use it?\n",
    "\n",
    "  **Answer:** Yes. For practically any model of interest (non-conjugate, hierarchical, latent variable) HMC is the  least complicated sampler you can use in order to perform reliable Bayesian inference.<br><br>\n",
    "\n",
    "2. **Question:** Ok, but can I treat the theory as a black-box, i.e. can I just press some `model.sample()` button?\n",
    "\n",
    "  **Answer:** No. HMC (just like all samplers) must be tuned. That is, for many models and datasets, `model.sample()` will not have good performance. You need the theory to tell you which design choices need to be adjusted and in what way.<br><br>\n",
    "  \n",
    "3. **Question:** But I don't need to implement it since `pymc3` has already done so, right?\n",
    "\n",
    "  **Answer:** You'll need to implement HMC. This is because `pymc3` is not going to scale well for Bayesian inference for models with neural network likelihoods and large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## HMC for Multimodal Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video height=\"440\" controls><source src=\"fig/hmc_multimodal.mov\" type=\"video/mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"<video height=\"440\" controls><source src=\"fig/hmc_multimodal.mov\" type=\"video/mp4\"></video>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Signs of Maybe Convergence?\n",
    "\n",
    "Look for:\n",
    "1. Large segments of the chain should have give similar statistics (mean, variance etc)\n",
    "2. Low correlations within states of the chain\n",
    "3. \"Reasonably high\" acceptance rate of proposed steps\n",
    "4. Multiple chains initialized from different initial points give similar results\n",
    "\n",
    "Best practics:\n",
    "1. Always run multiple chains initialized from very different random starting points\n",
    "2. Always run your chains for as long as you can then burn and thin\n",
    "3. Always check all relevant convergence diagnostics\n",
    "4. Never be too certain: remember that there is no \"proof\" of convergence for finite chains!\n",
    "5. Keep reading about best practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visual Diagnostics: Traceplots of Multiple Chains\n",
    "\n",
    "<img src=\"fig/multichain.jpg\" style=\"height:400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Autocorrelation: the \"Effective\" Sample Size\n",
    "\n",
    "We quantify how much the samples in the chain are correlated with the samples obtained $k$-steps later (**the $k$-th lag**). The ***autocorrelation*** $\\rho_k$ is defined as\n",
    "\n",
    "$$\n",
    "\\rho_k = \\frac{\\sum_{n=1}^{N-k}(x_n - \\bar{x})(x_{n+k} - \\bar{x})}{\\sum_{n=1}^{N}(x_n - \\bar{x})^2}\n",
    "$$\n",
    "\n",
    "We plot the autocorrelation for each $k = 1, \\ldots, \\frac{N}{2}$, and this ***autocorrelation plot*** tells us how much we to thin in order to obtain effectively independent samples. The autocorrelation plot gives us an idea of the ***effective sample size*** of the Markov chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visual Diagnostics: The Autocorrelation Plot\n",
    "\n",
    "<img src=\"fig/autocorr.jpg\" style=\"height:400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quantitative Diagnostics\n",
    "\n",
    "**Idea:** measure between-chain and within-chain variability of a quantity of interest â€“ if the chains have converged, these measures will be similar; otherwise, the between-chain variability will be larger.\n",
    "\n",
    "1. ***Gelman & Rubin***: quantity $\\widehat{R}_{\\text{GR}} =  \\frac{B}{W}$, which compares $B$ the empirical variance of all the chains pooled and $W$ the average emprical variance within each chain. If $\\widehat{R}_{\\text{GR}}$ is large then the chains are very different (not converged). If $\\widehat{R}_{\\text{GR}} = 1$ is ideal but in practice we accept $\\widehat{R}_{\\text{GR}} < 1.05$.<br><br>\n",
    "\n",
    "2. ***Geweke***: takes two nonoverlapping parts (usually the first 0.1 and last 0.5 proportions) of the Markov chain and compares the means of both parts, using a difference of means test to see if the two parts of the chain are from the same distribution (the test statistic is a standard Z-score with the standard errors adjusted for autocorrelation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parallel Tempering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multimodal Posteriors\n",
    "\n",
    "But when are posteriors multimodal? Often, the posterior can be multimodal when the likelihood is ***non-identifiable***, i.e. there are multiple sets of model parameters that can explain the data equally well.\n",
    "\n",
    "For example, the observed data likelihood of a Gaussian mixture model with 2 univariate components is: \n",
    "\n",
    "$$\n",
    "p(y|\\mu, \\sigma^2, \\pi) = \\pi_1 \\mathcal{N}(y; \\mu_1, \\sigma^2_1) + \\pi_2 \\mathcal{N}(y; \\mu_2, \\sigma^2_2)\n",
    "$$\n",
    "\n",
    "But, given an observation $y$, there are multiple sets of model parameters $\\mu, \\sigma^2, \\pi$ that will fit the data:\n",
    "\n",
    "$$\n",
    "0.1 \\mathcal{N}(y; 1, 0.5) + 0.9 \\mathcal{N}(y; -2, 1) = 0.9 \\mathcal{N}(y; -2, 1) + 0.1 \\mathcal{N}(y; 1, 0.5)\n",
    "$$\n",
    "\n",
    "That is, we can label the components however we want without changing the fit. \n",
    "\n",
    "When we fit a Bayesian GMM, the posterior will contain multiple modes, one for each way of labeling the components. \n",
    "\n",
    "**Note:** There are more non-trivial ways in which the likelihood of a GMM can be non-identifiable and, hence, its posterior multimodal! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Effect of Temperature\n",
    "\n",
    "Why is it hard for samplers to visit multiple modes in a target distribution? \n",
    "\n",
    "MCMC samplers can only propose locally, so moving from one mode to another requires traveling through regions that are very unlikely under the target distribution. \n",
    "\n",
    "In HMC terms, moving from one mode to another requires climbing a big hill -- this is called an ***energy barrier***. From simulated annealing we know that range of movement of a sampler of a Gibbs distribution is enhanced when we increase the temperature term:\n",
    "\n",
    "$$\n",
    "\\pi(q) = \\frac{1}{Z}\\exp\\left\\{ -\\frac{-\\log\\pi(q)}{T}\\right\\} \n",
    "$$\n",
    "\n",
    "Another way to say this is that when temperature is high, the poential energy landscape $\\frac{-\\log\\pi(q)}{T}$ is flat, hence easier to explore.\n",
    "\n",
    "But we can't simply set $T > 1$! Doing so means that we will not be sampling from the target $\\pi(q)$ (i.e. the above equation will not hold)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Idea of Parallel Tempering\n",
    "\n",
    "Using one MCMC chain with $T>1$ will produce incorrect samples. What if we use multiple chains: one for $T=1$ (which will produce samples from $\\pi(q)$) and other chains with $T>1$, and we allow the chains to exchange samples once in a while?\n",
    "\n",
    "<img src=\"fig/tempering.jpg\" style=\"height:300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel Tempering with HMC\n",
    "\n",
    "We set an increasing sequence of temperatures $T_0=1, \\ldots, T_M >1$. For each temperature, denote the corresponding Gibbs distribution and potential energy function as follows:\n",
    "$$\n",
    "\\pi_m(q) = \\frac{1}{Z}\\exp\\left\\{ -U_m(q)\\right\\}, \\; U_m(q) = \\frac{-\\log\\pi(q)}{T_m}\n",
    "$$\n",
    "We denote the potential energy of $\\pi(q)$ as $U(q) = -\\log\\pi(q)$.\n",
    "\n",
    "**Parallel Tempering HMC**\n",
    "\n",
    "**1.** initialize $M$ number of HMC samplers: each using the same kinetic energy function, the $m$-th sampler using the potential energy function $U_m(q)$.\n",
    "\n",
    "**2.**  alternate between:<br>\n",
    "$\\quad$**a.**  sample $S$ samples from each chain independently<br>\n",
    "$\\quad$**b.**  at the $S$-sample, the sample $q^{S}_{m+1}$ from chain $m + 1$ is exchanged with the sample $q^{S}_{m}$ from chain $m$ with the probability: \n",
    "  \n",
    "  $$\n",
    "  \\alpha = \\min\\left\\{1, \\exp \\left\\{(1/T_{m} - 1/T_{m+1})(U(q^{S}_m) - U(q^{S}_{m+1}))\\right\\}\\right\\}\n",
    "  $$\n",
    "  \n",
    "In the end, we keep the samples in the $0$-th chain.\n",
    "\n",
    "Can you show that parallel tempering is detailed balanced? What about irreducible and aperiodic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
